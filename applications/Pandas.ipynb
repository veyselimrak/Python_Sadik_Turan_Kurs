{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b280f5a8",
   "metadata": {},
   "source": [
    "Pandas Nedir ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f54e87e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pandas ile alÄ±nan verilerin analizi yapÄ±lÄ±r.\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "044baa97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# import numpy as np\n",
    "# #data\n",
    "# numbers = [20,30,40,50]\n",
    "# letters = ['a','b','c',20]\n",
    "# scalar = 5\n",
    "\n",
    "#Pandas Serileri eÅŸli olarak Ã§alÄ±ÅŸÄ±r index - value tipinde Ã§alÄ±ÅŸÄ±r.\n",
    "\n",
    "# # pandas_series = pd.Series(letters)\n",
    "# # pandas_series = pd.Series(scalar, [0,1,2,3]) # verilen index kadar scalar deÄŸer arttÄ±rÄ±lÄ±r.\n",
    "# # pandas_series = pd.Series(numbers, ['a','b','c','d'])\n",
    "# dict = {'a':10,'b':20,'c':30,'d':40}\n",
    "# # pandas_series = pd.Series(dict)\n",
    "# random_numbers = np.random.randint(10,100,6)\n",
    "# pandas_series = pd.Series([20,30,40,50],['a','b','c','d'])\n",
    "\n",
    "\n",
    "# # result = pandas_series[['a','c']]\n",
    "# result = pandas_series.ndim\n",
    "# result = pandas_series.dtype\n",
    "# result = pandas_series.shape\n",
    "# result = pandas_series.sum() # deÄŸerlerin toplamÄ±nÄ± verir.\n",
    "# result = pandas_series.max()\n",
    "# result = pandas_series + pandas_series\n",
    "# result = np.sqrt(pandas_series)\n",
    "# result = pandas_series >= 50\n",
    "# result = pandas_series % 2 == 0\n",
    "\n",
    "# print(pandas_series[result])\n",
    "# print(pandas_series)\n",
    "# print(result)\n",
    "\n",
    "\n",
    "opel2018 = pd.Series([20,30,40,10],[\"astra\",\"corsa\",\"mokka\",\"insigne\"])\n",
    "opel2019 = pd.Series([40,30,20,10],[\"astra\",\"corsa\",\"Granland\",\"insigne\"])\n",
    "total = opel2018 + opel2019\n",
    "print(total[\"astra\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e65296d2",
   "metadata": {},
   "source": [
    "Pandas DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9027adda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Name  Grade\n",
      "1   Ahmet   50.0\n",
      "2     Ali   60.0\n",
      "3  YaÄŸmur   70.0\n",
      "4   Ã‡Ä±nar   80.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\veyse\\AppData\\Local\\Temp\\ipykernel_8964\\2161852337.py:18: FutureWarning: Could not cast to float64, falling back to object. This behavior is deprecated. In a future version, when a dtype is passed to 'DataFrame', either all columns will be cast to that dtype, or a TypeError will be raised.\n",
      "  df = pd.DataFrame(data , columns = ['Name','Grade'], index = [1,2,3,4], dtype=float)\n"
     ]
    }
   ],
   "source": [
    "# # seriler gibi ama ayrÄ±calÄ±k olarak json dosyasÄ±nÄ± alÄ±p Ã§evirme iÅŸlemini yapabiliriz.\n",
    "# #Data framelerde datalara kolon baÅŸlÄ±ÄŸÄ± eklenebilir.\n",
    "# import pandas as pd\n",
    "\n",
    "data = [[\"Ahmet\",50],[\"Ali\",60],[\"YaÄŸmur\",70],[\"Ã‡Ä±nar\",80]]\n",
    "# dict = {\"Name\" : [\"Ahmet\",\"Ali\",\"YaÄŸmur\",\"Ã‡Ä±nar\"], \"Grade\" : [50,60,70,8]}\n",
    "# dict_list = [\n",
    "#     {\"Name\": \"Ahmet\",\"Grade\": 50},\n",
    "#     {\"Name\": \"Ali\",\"Grade\": 60},\n",
    "#     {\"Name\": \"YaÄŸmur\",\"Grade\": 70},\n",
    "#     {\"Name\": \"Ã‡Ä±nar\",\"Grade\": 0},\n",
    "    \n",
    "# ]\n",
    "\n",
    "\n",
    "# # df = pd.DataFrame()\n",
    "# # df = pd.DataFrame([1,2,3,4]) #baÅŸlÄ±k tanÄ±mlanmaz ise default olarak 0 verir.\n",
    "df = pd.DataFrame(data , columns = ['Name','Grade'], index = [1,2,3,4], dtype=float)\n",
    "\n",
    "# df = pd.DataFrame(dict, index = [\"212\",\"232\",\"236\",\"456\"])\n",
    "\n",
    "# print(df)\n",
    "\n",
    "# # s1= pd.Series([3,2,0,1])\n",
    "# # s2= pd.Series([0,3,7,2])\n",
    "\n",
    "# # data = dict(apples = s1, oranges = s2)# verilere baÅŸlÄ±k eklenir.\n",
    "\n",
    "# # df = pd.DataFrame(data)\n",
    "\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8638dcef",
   "metadata": {},
   "source": [
    "Pandas ile FarklÄ± Tiplerden Veri Okuma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "43942d93",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                  dict_list = [\n",
      "    {\"Name\": \"Ahmet\"  Grade: 50}            NaN\n",
      "    {\"Name\": \"Ali\"    Grade: 60}            NaN\n",
      "    {\"Name\": \"YaÄŸmur\" Grade: 70}            NaN\n",
      "    {\"Name\": \"Ã‡Ä±nar\"  Grade: 0}             NaN\n",
      "]                     NaN                   NaN\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# df = pd.read_json('sample.json')\n",
    "# df = pd.read_excel('sample.xslx')\n",
    "df = pd.read_csv('sample.csv')\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f124f512",
   "metadata": {},
   "source": [
    "DataFrame'ler ile Ã§alÄ±ÅŸma (seÃ§me iÅŸlemleri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4ec5807b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Column1   Column2   Column3   Column4\n",
      "A  1.182247 -1.923407  0.435056  0.979625\n",
      "B  0.597685  1.618459 -2.003555  1.434513\n",
      "C  0.944671 -1.900898 -0.138120 -0.194709\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from numpy.random import randn\n",
    "\n",
    "df = pd.DataFrame(randn(3,3), index = [\"A\",\"B\",\"C\"], columns = [\"Column1\",\"Column2\",\"Column3\"])\n",
    "\n",
    "#SÃ¼tuna gÃ¶re seÃ§me iÅŸlemleri\n",
    "result = df\n",
    "result = df[\"Column1\"]\n",
    "result = type(df[\"Column1\"])\n",
    "result = df[[\"Column1\",\"Column2\"]]\n",
    "# satÄ±ra gÃ¶re seÃ§me iÅŸlemleri\n",
    "\n",
    "# loc[\"row\",\"column\"] tek baÅŸÄ±na wo--row gÃ¶nderilebilir.Column gÃ¶ndermek istersek row yerine \": ifadesini koymak gerekir.\"\n",
    "result = df.loc[\"A\"] #location kÄ±saltmasÄ±dÄ±r. a satÄ±rÄ±ndaki elemanlarÄ± getirir.\n",
    "result = type(df.loc[\"A\"])\n",
    "result = df.iloc[2] # indexte integer ile Ã§alÄ±ÅŸmak istiyorsak kullanÄ±lÄ±r.\n",
    "result = df.loc[:,\"Column1\"]\n",
    "result = df.loc[:,[\"Column1\",\"Column2\"]]\n",
    "\n",
    "result = df.loc[:,\"Column1\":\"Column3\"] # aralÄ±k belirtilir. column1 ve 3 arasÄ±ndaki onlarda dahil olarak getirilir.\n",
    "result = df.loc[:,:\"Column3\"]\n",
    "result = df.loc[\"A\":\"B\",:\"Column3\"]\n",
    "\n",
    "result = df.loc[\"A\",\"Column2\"]\n",
    "result = df.loc[[\"A\",\"B\"],[\"Column1\",\"Column2\"]]\n",
    "\n",
    "\n",
    "df[\"Column4\"] = pd.Series(randn(3),[\"A\",\"B\",\"C\"])\n",
    "df[\"Column5\"] = df[\"Column1\"] + df[\"Column2\"]\n",
    "result = df.drop(\"Column5\", axis = 1, inplace = True)\n",
    "# drop silme iÅŸlemi yapar. kalÄ±cÄ± olarak deÄŸilde kopyasÄ±nÄ± Ã§Ä±karmak istersek inplace false olarak kullanÄ±rÄ±z default deÄŸeri zaten false.\n",
    "# kalÄ±cÄ± olarak silmek istersek inplace deÄŸerini true olarak deÄŸiÅŸtirebiliriz.\n",
    "\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eda829a",
   "metadata": {},
   "source": [
    "DateFrame Filtreleme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "8a0228d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Column1  Column2\n",
      "4       56       68\n",
      "5       92       98\n",
      "7       64       48\n",
      "9       64       55\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data = np.random.randint(10,100,75).reshape(15,5)\n",
    "\n",
    "df = pd.DataFrame(data, columns = [\"Column1\",\"Column2\",\"Column3\",\"Column4\",\"Column5\"])\n",
    "\n",
    "result = df\n",
    "result = df.columns\n",
    "result = df.head(5)\n",
    "result = df.head(10) # baÅŸtan ilk 10 kayÄ±t getirilir.\n",
    "result = df.tail(5) # sondan ilk5 kayÄ±t getirilir.\n",
    "result = df[\"Column1\"].head(5) #Colummn1 in ilk 5 kaydÄ±nÄ± getirir.\n",
    "result = df.Column1.head(5) #alternatif olarak kulllanÄ±llabilir.\n",
    "result = df[[\"Column1\",\"Column3\"]].head(5)\n",
    "result = df[5:15][[\"Column1\",\"Column2\"]].tail(5)\n",
    "\n",
    "result = df > 50 \n",
    "result = df[df > 50]  # true false deÄŸilde sayÄ± olarak istersek\n",
    "result = df[df % 2 == 0]  # true false deÄŸilde sayÄ± olarak istersek\n",
    "result = df[df[\"Column1\"] > 50][[\"Column1\",\"Column2\"]]\n",
    "result = df[ (df[\"Column1\"] >= 50) & (df[\"Column1\"] <= 70)] # and yerine & kulllanÄ±lÄ±r.\n",
    "result = df[ (df[\"Column1\"] >= 50) & (df[\"Column2\"] <= 70)] # and yerine & kulllanÄ±lÄ±r.\n",
    "result = df[ (df[\"Column1\"] >= 50) | (df[\"Column2\"] <= 70)][[\"Column1\",\"Column2\"] ]# or yerine | kulllanÄ±lÄ±r.\n",
    "result = df.query(\"Column1 >= 50 & Column1 % 2 == 0\")[[\"Column1\",\"Column2\"]]\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f01bc7c8",
   "metadata": {},
   "source": [
    "Pandas Uygulama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ec474900",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('imdb.csv')\n",
    "\n",
    "result = df\n",
    "result = df.columns\n",
    "result = df.info # dataframe hakkÄ±nda bir bilgi getirir.\n",
    "result = df.head(5)\n",
    "result = df.head(10)\n",
    "result = df.tail(5)\n",
    "result = df.tail(10)\n",
    "result = df[\"Movie_Title\"].head(5)\n",
    "result = df[[\"Movie_Title\",\"Rating\"]].head(5)\n",
    "result = df[[\"Movie_Title\",\"Rating\"]].tail(7)\n",
    "result = df[5:10][[\"Movie_Title\",\"Rating\"]]\n",
    "result = df[df[\"Movie_Title\"] & [\"Rating\"] >= 8.0]# benim yaptÄ±ÄŸÄ±m\n",
    "result = df[df[\"Rating\"] >= 8.0][[\"Movie_Title\",\"Rating\"]].head(50)\n",
    "result = df.query(\"Mpvie_Title & Rating > 8.0\")\n",
    "result = df[ (df[\"year\"] >= 2014) & ( [\"year\"] <= 2015) ][[\"Movie_Title\",\"year\"]]\n",
    "result = df[ (df[\"Num_Reviews\"] > 100000) |((df[\"Rating\"]  >= 8.0 )& (df[\"Rating\"] <= 9))][[\"Movie_Tilte\",\"Num_Reviews\",\"Rating\"]]\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "021ff0d9",
   "metadata": {},
   "source": [
    "DataFrame ' lerde Groupby kullanÄ±mÄ±"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "70cf9ee4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sum     10500.0\n",
      "mean     5250.0\n",
      "amax     6500.0\n",
      "amin     4000.0\n",
      "Name: Muhasebe, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data = {\n",
    "    \"isimler\" : [\"Ahmet\",\"Can\",\"Hasan\",\"Cenk\",\"Ali\",\"RÄ±za\",\"Mustafa\"],\n",
    "    \"departman\" : [\"Ä°K\",\"Bilgi Ä°ÅŸlem\",\"Muhasebe\",\"Ä°K\",\"Bilgi Ä°ÅŸlem\",\"Muhasebe\",\"Bilgi Ä°ÅŸlem\"],\n",
    "    \"yas\"  : [30, 25, 45, 50, 23, 34, 42],\n",
    "    \"semt\" : [\"KadÄ±kÃ¶y\",\"Tuzla\",\"Maltepe\",\"Tuzla\",\"KadÄ±kÃ¶y\",\"Tuzla\",\"Maltepe\"],\n",
    "    \"maas\" : [5000, 3000, 4000, 3500, 2750, 6500, 4500]\n",
    "}\n",
    "        \n",
    "df = pd.DataFrame(data)\n",
    "result = df[\"maas\"].sum()\n",
    "result = df\n",
    "\n",
    "result = df.groupby(\"departman\").groups\n",
    "result = df.groupby([\"departman\",\"semt\"]).groups\n",
    "\n",
    "# for name,group in df.groupby(\"semt\"): # semt kolonundaki verileri gruplandÄ±rÄ±r.\n",
    "#     print(name)\n",
    "#     print(group)\n",
    "# for name,group in df.groupby(\"departman\"):\n",
    "#     print(name) #semt adÄ±\n",
    "#     print(group) # o semtte bulunan kiÅŸilerin verilerini gruplar\n",
    "\n",
    "result = df.groupby(\"semt\").get_group(\"KadÄ±kÃ¶y\") # SEMT GRUBUNUNN Ä°Ã‡Ä°NDEN KADIKÃ–YDE OLAN VERÄ°LERÄ° GETÄ°RÄ°R.\n",
    "result = df.groupby(\"departman\").get_group(\"Muhasebe\")\n",
    "\n",
    "result = df.groupby(\"departman\").sum()\n",
    "result = df.groupby(\"departman\").mean()\n",
    "result = df.groupby(\"departman\")[\"maas\"].mean()\n",
    "result = df.groupby(\"semt\")[\"yas\"].mean()\n",
    "result = df.groupby(\"semt\")[\"maas\"].mean()\n",
    "result = df.groupby(\"semt\")[\"isimler\"].count()\n",
    "result = df.groupby(\"departman\")[\"yas\"].max()\n",
    "result = df.groupby(\"departman\")[\"maas\"].min()[\"Muhasebe\"]\n",
    "\n",
    "result = df.groupby(\"departman\").agg(np.mean)\n",
    "result = df.groupby(\"departman\")[\"maas\"].agg([np.sum,np.mean,np.max,np.min]).loc[\"Muhasebe\"]\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8de650d8",
   "metadata": {},
   "source": [
    "Pandas ile KayÄ±p veya bozuk veri analizi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8a4dc5bb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Column1    Column2    Column3    Column4\n",
      "a  80.000000  43.000000  10.000000  43.578947\n",
      "b  43.578947  43.578947  43.578947  30.000000\n",
      "c  19.000000  69.000000  20.000000  43.578947\n",
      "d  43.578947  43.578947  43.578947  51.000000\n",
      "e  29.000000  18.000000  26.000000  43.578947\n",
      "f  77.000000  80.000000  68.000000  30.000000\n",
      "g  43.578947  43.578947  43.578947  43.578947\n",
      "h  17.000000  75.000000  76.000000  10.000000\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data = np.random.randint(10,100,15).reshape(5,3)\n",
    "df = pd.DataFrame(data, index = ['a','c','e','f','h'], columns = ['Column1','Column2','Column3'])\n",
    "df = df.reindex(['a','b','c','d','e','f','g','h'])\n",
    "\n",
    "newColumn = [np.nan,30,np.nan,51,np.nan,30,np.nan,10] \n",
    "df[\"Column4\"] = newColumn\n",
    "\n",
    "result = df\n",
    "\n",
    "result = df.drop([\"Column1\",\"Column2\"], axis = 1) # 0 satÄ±ra 1 ise sÃ¼tuna denk gelir.\n",
    "result = df.drop([\"a\"], axis = 0)\n",
    "\n",
    "\n",
    "result = df.isnull()\n",
    "result = df.notnull()# null olmayan alanlarÄ± getirir.\n",
    "\n",
    "result = df.isnull().sum()# null ise true deÄŸer dÃ¶ndÃ¼rÃ¼r. sum ile bunlar toplanÄ±r.\n",
    "result = df[df[\"Column1\"].isnull()]\n",
    "result = df[df[\"Column1\"].notnull()][\"Column1\"]\n",
    "\n",
    "\n",
    "result = df.dropna(axis = 1) # axis = 0 varsayÄ±lan olarak gelir.\n",
    "result = df.dropna(how  = \"any\") # en az bir tane varsa\n",
    "result = df.dropna(how  = \"all\") # hepsi null ise getirmez.\n",
    "result = df.dropna(subset = [\"Column1\",\"Column2\"],how = \"all\")# sadece Column1 ve Column2 de ara\n",
    "result = df.dropna(subset = [\"Column1\",\"Column2\"],how = \"any\")\n",
    "result = df.dropna(thresh = 2) #en az 2 tane deÄŸer varsa silmez.\n",
    "result = df.dropna(thresh = 3)\n",
    "\n",
    "result = df.fillna(value = \"no input\") # boÅŸ alanlara no input yazar.\n",
    "\n",
    "result = df.sum() # her sÃ¼tundaki sayÄ±larÄ±n toplamÄ±nÄ± getirir.\n",
    "result = df.sum().sum() # toplam sayÄ±sal deÄŸeri verir.\n",
    "result = df.size\n",
    "result = df.isnull().sum()\n",
    "result = df.isnull().sum().sum()\n",
    "\n",
    "\n",
    "def ortalama(df):\n",
    "    toplam = df.sum().sum()\n",
    "    adet = df.size - df.isnull().sum().sum()\n",
    "    return toplam / adet\n",
    "\n",
    "result = df.fillna(value = ortalama(df))\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1228ea68",
   "metadata": {},
   "source": [
    "Pandas ile String FonksiyonlarÄ±"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "642f83f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv(\"nba.csv\")\n",
    "\n",
    "data.dropna(inplace = True)\n",
    "\n",
    "data[\"Name\"] = data[\"Name\"].str.upper() # str yazdÄ±ktan sonra string metotlarÄ±na ulaÅŸÄ±labilir.\n",
    "data[\"Name\"] = data[\"Name\"].str.lower()\n",
    "data[\"index\"] = data[\"Name\"].str.find('a')\n",
    "data = data.Name.str.contains(\"Jordan\")\n",
    "data = data.Team.str.replace(' ','-')\n",
    "data[[\"FirstName\",\"LastName\"]] = data[\"Name\"].loc[data[\"Name\"].str.split().str.len() == 2].str.split(expand==True)\n",
    "\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2f9baf9",
   "metadata": {},
   "source": [
    "Pandas ile Join ve Merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e3a3a2f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   CustemorId FirstName LastName\n",
      "0           1     Ahmet   YÄ±lmaz\n",
      "1           2       Ali  Korkmaz\n",
      "2           3     Hasan    Ã‡elik\n",
      "3           4     Canan   Toprak\n",
      "0           1     Ahmet   YÄ±lmaz\n",
      "1           2       Ali  Korkmaz\n",
      "2           3     Hasan    Ã‡elik\n",
      "3           4     Canan   Toprak\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# customers = {\n",
    "#     'CustemorId': [1,2,3,4],\n",
    "#     'FirstName' : [\"Ahmet\",\"Ali\",\"Hasan\",\"Canan\"],\n",
    "#     \"LastName\" : [\"YÄ±lmaz\",\"Korkmaz\",\"Ã‡elik\",\"Toprak\"]\n",
    "# }\n",
    "# orders = {\n",
    "#     'OrderId': [10,11,12,13],\n",
    "#     'CustemorId': [1,2,5,7],\n",
    "#     'OrderDate' : ['2010-07-04' , '2010-07-07','2012-07-04','2000-11-04']\n",
    "# }\n",
    "\n",
    "# df_customers = pd.DataFrame(customers, columns = [\"CustemorId\",\"FirstName\",\"LastName\"])\n",
    "# df_orders = pd.DataFrame(orders, columns = [\"OrderId\", \"CustemorId\",\"OrderDate\"])\n",
    "\n",
    "\n",
    "# print(df_customers)\n",
    "# print(df_orders)\n",
    "\n",
    "# result = pd.merge(df_customers,df_orders,how = \"inner\") #2 tablo birleÅŸtirilir.\n",
    "# result = pd.merge(df_customers,df_orders,how = \"left\") # soldakileri getir saÄŸdakileri getirme\n",
    "# result = pd.merge(df_customers,df_orders,how = \"right\") # aynÄ± ÅŸekilde saÄŸdakileri getir.\n",
    "\n",
    "\n",
    "customersA = {\n",
    "    'CustemorId': [1,2,3,4],\n",
    "    'FirstName' : [\"Ahmet\",\"Ali\",\"Hasan\",\"Canan\"],\n",
    "    \"LastName\" : [\"YÄ±lmaz\",\"Korkmaz\",\"Ã‡elik\",\"Toprak\"]\n",
    "}\n",
    "customersB = {\n",
    "    'CustemorId': [5,6,7,8],\n",
    "    'FirstName' : [\"YaÄŸmur\",\"Ã‡Ä±nar\",\"Cengiz\",\"Can\"],\n",
    "    \"LastName\" : [\"Bilge\",\"Turan\",\"YÄ±lmaz\",\"Turan\"]\n",
    "}\n",
    "\n",
    "df_customersA = pd.DataFrame(customers, columns = [\"CustemorId\",\"FirstName\",\"LastName\"])\n",
    "df_customersB = pd.DataFrame(customers, columns = [\"CustemorId\",\"FirstName\",\"LastName\"])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "result = pd.concat([df_customersA,df_customersB])\n",
    "# BirleÅŸtirme iÅŸlemi yapÄ±lÄ±r.\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74658897",
   "metadata": {},
   "source": [
    "Pandas ile DataFrame MetotlarÄ±"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5858872d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kategori  Elektronik  Kitap\n",
      "Ay                         \n",
      "Haziran           41     34\n",
      "MayÄ±s             20     13\n",
      "Nisan             15     42\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# data = {\n",
    "#     \"Column1\" : [1,2,3,4,5],\n",
    "#     \"Column2\" : [10,20,13,45,25],\n",
    "#     \"Column3\" : [\"abc\",\"ca\",\"aded\",\"ba\",\"dea\"]\n",
    "# }\n",
    "\n",
    "# df = pd.DataFrame(data)\n",
    "# result = df\n",
    "# result = df[\"Column2\"].unique() # tekrarlanmayan deÄŸerleri getirir.\n",
    "# result = df[\"Column2\"].nunique() # tekrarlanmayan deÄŸerlerin sayÄ±sÄ±nÄ± getirir.\n",
    "# result = df[\"Column2\"].value_counts() # eleman sayÄ±sÄ±nÄ± verir.\n",
    "# result = df[\"Column1\"] * 2\n",
    "\n",
    "\n",
    "# def kareal(x):\n",
    "#     return x * x\n",
    "# kareal2 = lambda x: x * x\n",
    "\n",
    "\n",
    "# result = df[\"Column1\"].apply(kareal2) # apply metoduna fonksiyon gÃ¶nderilebilir teker teker fonksiyona deÄŸerler gider.\n",
    "# df[\"Column4\"] = df[\"Column3\"].apply(len)\n",
    "\n",
    "# result = df.columns\n",
    "# result = len(df.columns)\n",
    "# result = len(df.index)\n",
    "\n",
    "\n",
    "# result = df.info\n",
    "# result = df.sort_values(\"Column2\")\n",
    "# result = df.sort_values(\"Column3\",ascending = False) # ascending false artandan azalana doÄŸru sÄ±ralar.\n",
    "\n",
    "data = {\n",
    "    \"Ay\" : [\"MayÄ±s\",\"Haziran\",\"Nisan\",\"MayÄ±s\",\"Haziran\",\"Nisan\",\"MayÄ±s\",\"Haziran\",\"Haziran\"],\n",
    "    \"Kategori\" : [\"Elektronik\",\"Elektronik\",\"Elektronik\",\"Kitap\",\"Kitap\",\"Kitap\",\"Kitap\",\"Kitap\",\"Elektronik\"],\n",
    "    \"Gelir\" : [20,30,15,14,32,42,12,36,52]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "df = df.pivot_table(index=\"Ay\",columns = \"Kategori\", values = \"Gelir\")\n",
    "\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2930e75d",
   "metadata": {},
   "source": [
    "Nba Verileri (Uygulama)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "538ba1b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Name                    Team  Number Position   Age Height  \\\n",
      "52        Carl Landry      Philadelphia 76ers     7.0       PF  32.0    6-9   \n",
      "78       Andrew Bogut   Golden State Warriors    12.0        C  31.0    7-0   \n",
      "83     Andre Iguodala   Golden State Warriors     9.0       SF  32.0    6-6   \n",
      "87       Brandon Rush   Golden State Warriors     4.0       SF  30.0    6-6   \n",
      "94     Branden Dawson    Los Angeles Clippers    22.0       SF  23.0    6-6   \n",
      "98     DeAndre Jordan    Los Angeles Clippers     6.0        C  27.0   6-11   \n",
      "106      Brandon Bass      Los Angeles Lakers     2.0       PF  31.0    6-8   \n",
      "115     Julius Randle      Los Angeles Lakers    30.0       PF  21.0    6-9   \n",
      "127    Brandon Knight            Phoenix Suns     3.0       PG  24.0    6-3   \n",
      "137    James Anderson        Sacramento Kings     5.0       SG  27.0    6-6   \n",
      "149     Eric Moreland        Sacramento Kings    25.0       PF  24.0   6-10   \n",
      "188    Andre Drummond         Detroit Pistons     0.0        C  22.0   6-11   \n",
      "227   Justin Anderson        Dallas Mavericks     1.0       SG  22.0    6-6   \n",
      "238  Chandler Parsons        Dallas Mavericks    25.0       SF  27.0   6-10   \n",
      "248  Andrew Goudelock         Houston Rockets     0.0       PG  27.0    6-3   \n",
      "259    Chris Andersen       Memphis Grizzlies     7.0       PF  37.0   6-10   \n",
      "271     Zach Randolph       Memphis Grizzlies    50.0       PF  34.0    6-9   \n",
      "274    Brandan Wright       Memphis Grizzlies    34.0       PF  28.0   6-10   \n",
      "276     Ryan Anderson    New Orleans Pelicans    33.0       PF  28.0   6-10   \n",
      "291   Orlando Johnson    New Orleans Pelicans     0.0       SG  27.0    6-5   \n",
      "295     Kyle Anderson       San Antonio Spurs     1.0       SF  22.0    6-9   \n",
      "304      Andre Miller       San Antonio Spurs    24.0       PG  40.0    6-3   \n",
      "362  Andrew Nicholson           Orlando Magic    44.0       PF  26.0    6-9   \n",
      "368     Alan Anderson      Washington Wizards     6.0       SG  33.0    6-6   \n",
      "386   Wilson Chandler          Denver Nuggets    21.0       SF  29.0    6-8   \n",
      "411    Andrew Wiggins  Minnesota Timberwolves    22.0       SG  21.0    6-8   \n",
      "415        Randy Foye   Oklahoma City Thunder     6.0       SG  32.0    6-4   \n",
      "423    Andre Roberson   Oklahoma City Thunder    21.0       SG  24.0    6-7   \n",
      "427   Cliff Alexander  Portland Trail Blazers    34.0       PF  20.0    6-8   \n",
      "\n",
      "     Weight           College      Salary  \n",
      "52    248.0            Purdue   6500000.0  \n",
      "78    260.0              Utah  13800000.0  \n",
      "83    215.0           Arizona  11710456.0  \n",
      "87    220.0            Kansas   1270964.0  \n",
      "94    225.0    Michigan State    525093.0  \n",
      "98    265.0         Texas A&M  19689000.0  \n",
      "106   250.0               LSU   3000000.0  \n",
      "115   250.0          Kentucky   3132240.0  \n",
      "127   189.0          Kentucky  13500000.0  \n",
      "137   213.0    Oklahoma State   1015421.0  \n",
      "149   238.0      Oregon State    845059.0  \n",
      "188   279.0       Connecticut   3272091.0  \n",
      "227   228.0          Virginia   1449000.0  \n",
      "238   230.0           Florida  15361500.0  \n",
      "248   200.0        Charleston    200600.0  \n",
      "259   245.0     Blinn College   5000000.0  \n",
      "271   260.0    Michigan State   9638555.0  \n",
      "274   210.0    North Carolina   5464000.0  \n",
      "276   240.0        California   8500000.0  \n",
      "291   220.0  UC Santa Barbara     55722.0  \n",
      "295   230.0              UCLA   1142880.0  \n",
      "304   200.0              Utah    250750.0  \n",
      "362   250.0   St. Bonaventure   2380593.0  \n",
      "368   220.0    Michigan State   4000000.0  \n",
      "386   225.0            DePaul  10449438.0  \n",
      "411   199.0            Kansas   5758680.0  \n",
      "415   213.0         Villanova   3135000.0  \n",
      "423   210.0          Colorado   1210800.0  \n",
      "427   240.0            Kansas    525093.0  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv(\"nba.csv\")\n",
    "\n",
    "result = df\n",
    "\n",
    "result = df.head(10)\n",
    "result = len(df.index)\n",
    "result = df[\"Salary\"].mean()\n",
    "result = df[\"Salary\"].max()\n",
    "result = df[\"Salary\"].max()\n",
    "result = df[df[\"Salary\"] == df[\"Salary\"].max()][\"Name\"].iloc[0]\n",
    "result = (df[(df[\"Age\"] >= 20 ) & (df[\"Age\"] < 25)])[[\"Name\",\"Team\",\"Age\"]]\n",
    "result = df[df[\"Name\"] == \"John Holland\"][\"Team\"]\n",
    "result = df.groupby(\"Team\")[\"Salary\"].mean()\n",
    "result = len(df.groupby(\"Team\"))\n",
    "result = df[\"Team\"].nunique()\n",
    "result = df[\"Team\"].value_counts()\n",
    "\n",
    "df.dropna(inplace = True) # null deÄŸerler silinir\n",
    "result = df[df[\"Name\"].str.contains(\"and\")]\n",
    "\n",
    "\n",
    "\n",
    "def str_find(name):\n",
    "    if \"and\" in name.lower():\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "result = df[df[\"Name\"].apply(str_find)] # str_find referans olarak gÃ¶nderilir.\n",
    "\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b649e951",
   "metadata": {},
   "source": [
    "Youtube istatistik verilerin analizi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "2a7a3d69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          video_id trending_date  \\\n",
      "36631  N1HAMUAXzbs      18.01.06   \n",
      "7088   sVfTvLm-7Ac      17.19.12   \n",
      "5361   vPsic3dEndc      17.10.12   \n",
      "12082  6W45zR0knjg      18.15.01   \n",
      "5338   r81egea0QPo      17.10.12   \n",
      "...            ...           ...   \n",
      "21547  BhIEIO0vaBE      18.03.03   \n",
      "22661  c0arVTRwytA      18.09.03   \n",
      "24920  ixNNLvyCn5Y      18.20.03   \n",
      "14864  nQ7mhC5_Rys      18.29.01   \n",
      "4465   nx1R-eHSkfM      17.06.12   \n",
      "\n",
      "                                                   title       channel_title  \\\n",
      "36631         Kris Wu â€“ Like That (Official Music Video)             Kris Wu   \n",
      "7088      HIGHLIGHTS: MK Dons U18s 1-0 Cardiff City U18s             MK Dons   \n",
      "5361         QUIZ : Name the Trail : A Christmas Cracker   The 2Inch of Gnar   \n",
      "12082    Lima Sopoaga TributeðŸ”¥ðŸ”¥||The Unsung Hero||ðŸ’¯ 2017   The rugby channel   \n",
      "5338   Bohemian Rhapsody (2018) - Scene Bohemian Rhap...      NanoO ARCHIVOS   \n",
      "...                                                  ...                 ...   \n",
      "21547                                    To Our Daughter        Kylie Jenner   \n",
      "22661                      ã€å…¬å¼ã€‘ã€ŒåŠ‡å ´ç‰ˆãƒã‚±ãƒƒãƒˆãƒ¢ãƒ³ã‚¹ã‚¿ãƒ¼ ã¿ã‚“ãªã®ç‰©èªžã€äºˆå‘Šç·¨1  ãƒã‚±ãƒ¢ãƒ³å…¬å¼YouTubeãƒãƒ£ãƒ³ãƒãƒ«   \n",
      "24920                    æ˜ ç”»ã€ŽBLEACHã€ç‰¹å ±ã€HDã€‘2018å¹´7æœˆ20æ—¥ï¼ˆé‡‘ï¼‰å…¬é–‹  ãƒ¯ãƒ¼ãƒŠãƒ¼ ãƒ–ãƒ©ã‚¶ãƒ¼ã‚¹ å…¬å¼ãƒãƒ£ãƒ³ãƒãƒ«   \n",
      "14864                             Altwork 1 Minute Video             altwork   \n",
      "4465                      The New Snapchat in 60 Seconds            Snapchat   \n",
      "\n",
      "       category_id              publish_time  \\\n",
      "36631           10  2018-05-22T15:05:18.000Z   \n",
      "7088            17  2017-12-13T16:33:57.000Z   \n",
      "5361            22  2017-12-01T11:34:30.000Z   \n",
      "12082           17  2017-09-29T21:46:38.000Z   \n",
      "5338             1  2017-11-02T18:30:38.000Z   \n",
      "...            ...                       ...   \n",
      "21547           22  2018-02-04T20:27:38.000Z   \n",
      "22661            1  2018-02-27T01:00:03.000Z   \n",
      "24920            1  2018-02-21T05:17:53.000Z   \n",
      "14864           28  2017-01-21T00:12:02.000Z   \n",
      "4465            10  2017-11-29T14:00:03.000Z   \n",
      "\n",
      "                                                    tags     views  likes  \\\n",
      "36631  Kris Wu|\"Wu Yi Fan\"|\"å´äº¦å‡¡\"|\"fan shi\"|\"wuyifan\"|...  12230325  57544   \n",
      "7088                 Tommy Hope|\"MK Dons\"|\"Cardiff City\"     21530     30   \n",
      "5361   MTB|\"Mountain Biking\"|\"Bike\"|\"Bird\"|\"Aeris\"|\"B...      1218      2   \n",
      "12082                                             [none]     10869     50   \n",
      "5338   Bohemian Rhapsody Live AID|\"freddie mercury fi...     10142     71   \n",
      "...                                                  ...       ...    ...   \n",
      "21547  Kylie Jenner|\"Kylie\"|\"Travis Scott\"|\"Baby\"|\"An...  61080912      0   \n",
      "22661  pokemon|\"PokÃ©mon\"|\"ãƒã‚±ãƒ¢ãƒ³\"|\"ãƒã‚±ãƒƒãƒˆãƒ¢ãƒ³ã‚¹ã‚¿ãƒ¼\"|\"ã¿ã‚“ãªã®ç‰©èªž\"|...   1234846      0   \n",
      "24920  ãƒ–ãƒªãƒ¼ãƒ|\"BLEACH\"|\"ç¦å£«è’¼æ±°\"|\"ä½è—¤ä¿¡ä»‹\"|\"é€±åˆŠå°‘å¹´ã‚¸ãƒ£ãƒ³ãƒ—\"|\"å®Œçµ\"|\"ä¹…...   1421802      0   \n",
      "14864                                             [none]     50522      0   \n",
      "4465   new snapchat|\"version 2\"|\"snap inc\"|\"brandnew\"...   3449247      0   \n",
      "\n",
      "       dislikes  comment_count  video_error_or_removed  \\\n",
      "36631         0           9528                   False   \n",
      "7088          0              2                   False   \n",
      "5361          0              1                   False   \n",
      "12082         0             14                   False   \n",
      "5338          0             20                   False   \n",
      "...         ...            ...                     ...   \n",
      "21547         0              0                   False   \n",
      "22661         0              0                   False   \n",
      "24920         0              0                   False   \n",
      "14864         0              0                   False   \n",
      "4465          0              0                   False   \n",
      "\n",
      "                                             description  title_len  \\\n",
      "36631  Special thanks to Stella Maxwell.Get â€œLike Tha...         42   \n",
      "7088   Check out Tommy Hope's stunning winner in the ...         46   \n",
      "5361   A Bad Brains Christmas Cracker! - #NameTheTrai...         43   \n",
      "12082  Hope You Enjoyed The Video \\n-----------------...         47   \n",
      "5338   Queen - Bohemian Rhapsody Live AID \\n\\nSUSCRIB...         59   \n",
      "...                                                  ...        ...   \n",
      "21547  Directed by Tyler Ross @wttyler\\nMusic by Jaco...         15   \n",
      "22661  2018å¹´7æœˆ13æ—¥ï¼ˆé‡‘ï¼‰å…¬é–‹ ã€ŒåŠ‡å ´ç‰ˆãƒã‚±ãƒƒãƒˆãƒ¢ãƒ³ã‚¹ã‚¿ãƒ¼ ã¿ã‚“ãªã®ç‰©èªžã€\\næ˜ ç”»å…¬å¼ã‚µã‚¤ãƒˆ...         29   \n",
      "24920  æ­»ç¥žã€è¦‹å‚ã€‚\\n\\nå…¨ä¸–ç•Œç´¯è¨ˆç™ºè¡Œéƒ¨æ•°1å„„2,000ä¸‡éƒ¨ã®å›½æ°‘çš„äººæ°—ã‚³ãƒŸãƒƒã‚¯ãŒå®Ÿå†™æ˜ ç”»åŒ–ï¼æ‚ª...         31   \n",
      "14864                                                NaN         22   \n",
      "4465   Evan Spiegel, co-founder and CEO, explains the...         30   \n",
      "\n",
      "       tag_count  begeni_orani  \n",
      "36631          9           1.0  \n",
      "7088           3           1.0  \n",
      "5361          22           1.0  \n",
      "12082          1           1.0  \n",
      "5338          16           1.0  \n",
      "...          ...           ...  \n",
      "21547          5           0.0  \n",
      "22661         18           0.0  \n",
      "24920         25           0.0  \n",
      "14864          1           0.0  \n",
      "4465          11           0.0  \n",
      "\n",
      "[38916 rows x 16 columns]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_10292\\3100592909.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"begeni_orani\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlikedislikeoranhesapla\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 47\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"begeni_orani\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mascending\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"title\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"dislikes\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"begeni_orani\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"youtube-ing.csv\")\n",
    "\n",
    "result = df\n",
    "result = df.head(10)\n",
    "result = df[5:10].head(5) # gruplayÄ±p kayÄ±tlarÄ±n ilk 5ini alÄ±rÄ±z.\n",
    "# result = len(df.columns.name)\n",
    "result = df.drop([\"thumbnail_link\",\"comments_disabled\",\"ratings_disabled\"] ,axis = 1,inplace=True)\n",
    "result = df\n",
    "result = df[\"likes\"].mean()\n",
    "result = df[\"dislikes\"].mean()\n",
    "result = df.head(50)[[\"title\",\"likes\",\"dislikes\"]]\n",
    "\n",
    "result = df [df[\"views\"].max() == df[\"views\"]][\"title\"].iloc[0]\n",
    "result = df [df[\"views\"].min() == df[\"views\"]][\"title\"].iloc[0]\n",
    "result = df.sort_values(\"views\",ascending = False).head(10)[\"title\"]\n",
    "\n",
    "\n",
    "result = df.groupby(\"category_id\").mean().sort_values(\"likes\")[\"likes\"]\n",
    "result = df.groupby(\"category_id\").sum().sort_values(\"comment_count\",ascending = False)\n",
    "\n",
    "result = df[\"category_id\"].value_counts()\n",
    "df[\"title_len\"] = df[\"title\"].apply(len)\n",
    "\n",
    "def tagCount(tag):\n",
    "    return len(tag.split(\"|\"))\n",
    "\n",
    "df[\"tag_count\"] = df[\"tags\"].apply(tagCount)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def likedislikeoranhesapla(dataset):\n",
    "    likesList = list(df[\"likes\"])\n",
    "    dislikesList = list(df[\"dislikes\"])\n",
    "    liste = list(zip(likesList,dislikesList))\n",
    "    oranListesi = []\n",
    "    for like,dislike in liste:\n",
    "        if (like + dislike) == 0:\n",
    "            oranListesi.append(0)\n",
    "        else:\n",
    "            oranListesi.append(like/(like+dislike))\n",
    "    return oranListesi\n",
    "    \n",
    "df[\"begeni_orani\"] = likedislikeoranhesapla(df)\n",
    "print(df.sort_values(\"begeni_orani\",ascending = False))[[\"title\",\"dislikes\",\"begeni_orani\"]]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
