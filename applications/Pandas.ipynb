{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b280f5a8",
   "metadata": {},
   "source": [
    "Pandas Nedir ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f54e87e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pandas ile alınan verilerin analizi yapılır.\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "044baa97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# import numpy as np\n",
    "# #data\n",
    "# numbers = [20,30,40,50]\n",
    "# letters = ['a','b','c',20]\n",
    "# scalar = 5\n",
    "\n",
    "#Pandas Serileri eşli olarak çalışır index - value tipinde çalışır.\n",
    "\n",
    "# # pandas_series = pd.Series(letters)\n",
    "# # pandas_series = pd.Series(scalar, [0,1,2,3]) # verilen index kadar scalar değer arttırılır.\n",
    "# # pandas_series = pd.Series(numbers, ['a','b','c','d'])\n",
    "# dict = {'a':10,'b':20,'c':30,'d':40}\n",
    "# # pandas_series = pd.Series(dict)\n",
    "# random_numbers = np.random.randint(10,100,6)\n",
    "# pandas_series = pd.Series([20,30,40,50],['a','b','c','d'])\n",
    "\n",
    "\n",
    "# # result = pandas_series[['a','c']]\n",
    "# result = pandas_series.ndim\n",
    "# result = pandas_series.dtype\n",
    "# result = pandas_series.shape\n",
    "# result = pandas_series.sum() # değerlerin toplamını verir.\n",
    "# result = pandas_series.max()\n",
    "# result = pandas_series + pandas_series\n",
    "# result = np.sqrt(pandas_series)\n",
    "# result = pandas_series >= 50\n",
    "# result = pandas_series % 2 == 0\n",
    "\n",
    "# print(pandas_series[result])\n",
    "# print(pandas_series)\n",
    "# print(result)\n",
    "\n",
    "\n",
    "opel2018 = pd.Series([20,30,40,10],[\"astra\",\"corsa\",\"mokka\",\"insigne\"])\n",
    "opel2019 = pd.Series([40,30,20,10],[\"astra\",\"corsa\",\"Granland\",\"insigne\"])\n",
    "total = opel2018 + opel2019\n",
    "print(total[\"astra\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e65296d2",
   "metadata": {},
   "source": [
    "Pandas DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9027adda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Name  Grade\n",
      "1   Ahmet   50.0\n",
      "2     Ali   60.0\n",
      "3  Yağmur   70.0\n",
      "4   Çınar   80.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\veyse\\AppData\\Local\\Temp\\ipykernel_8964\\2161852337.py:18: FutureWarning: Could not cast to float64, falling back to object. This behavior is deprecated. In a future version, when a dtype is passed to 'DataFrame', either all columns will be cast to that dtype, or a TypeError will be raised.\n",
      "  df = pd.DataFrame(data , columns = ['Name','Grade'], index = [1,2,3,4], dtype=float)\n"
     ]
    }
   ],
   "source": [
    "# # seriler gibi ama ayrıcalık olarak json dosyasını alıp çevirme işlemini yapabiliriz.\n",
    "# #Data framelerde datalara kolon başlığı eklenebilir.\n",
    "# import pandas as pd\n",
    "\n",
    "data = [[\"Ahmet\",50],[\"Ali\",60],[\"Yağmur\",70],[\"Çınar\",80]]\n",
    "# dict = {\"Name\" : [\"Ahmet\",\"Ali\",\"Yağmur\",\"Çınar\"], \"Grade\" : [50,60,70,8]}\n",
    "# dict_list = [\n",
    "#     {\"Name\": \"Ahmet\",\"Grade\": 50},\n",
    "#     {\"Name\": \"Ali\",\"Grade\": 60},\n",
    "#     {\"Name\": \"Yağmur\",\"Grade\": 70},\n",
    "#     {\"Name\": \"Çınar\",\"Grade\": 0},\n",
    "    \n",
    "# ]\n",
    "\n",
    "\n",
    "# # df = pd.DataFrame()\n",
    "# # df = pd.DataFrame([1,2,3,4]) #başlık tanımlanmaz ise default olarak 0 verir.\n",
    "df = pd.DataFrame(data , columns = ['Name','Grade'], index = [1,2,3,4], dtype=float)\n",
    "\n",
    "# df = pd.DataFrame(dict, index = [\"212\",\"232\",\"236\",\"456\"])\n",
    "\n",
    "# print(df)\n",
    "\n",
    "# # s1= pd.Series([3,2,0,1])\n",
    "# # s2= pd.Series([0,3,7,2])\n",
    "\n",
    "# # data = dict(apples = s1, oranges = s2)# verilere başlık eklenir.\n",
    "\n",
    "# # df = pd.DataFrame(data)\n",
    "\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8638dcef",
   "metadata": {},
   "source": [
    "Pandas ile Farklı Tiplerden Veri Okuma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "43942d93",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                  dict_list = [\n",
      "    {\"Name\": \"Ahmet\"  Grade: 50}            NaN\n",
      "    {\"Name\": \"Ali\"    Grade: 60}            NaN\n",
      "    {\"Name\": \"Yağmur\" Grade: 70}            NaN\n",
      "    {\"Name\": \"Çınar\"  Grade: 0}             NaN\n",
      "]                     NaN                   NaN\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# df = pd.read_json('sample.json')\n",
    "# df = pd.read_excel('sample.xslx')\n",
    "df = pd.read_csv('sample.csv')\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f124f512",
   "metadata": {},
   "source": [
    "DataFrame'ler ile çalışma (seçme işlemleri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4ec5807b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Column1   Column2   Column3   Column4\n",
      "A  1.182247 -1.923407  0.435056  0.979625\n",
      "B  0.597685  1.618459 -2.003555  1.434513\n",
      "C  0.944671 -1.900898 -0.138120 -0.194709\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from numpy.random import randn\n",
    "\n",
    "df = pd.DataFrame(randn(3,3), index = [\"A\",\"B\",\"C\"], columns = [\"Column1\",\"Column2\",\"Column3\"])\n",
    "\n",
    "#Sütuna göre seçme işlemleri\n",
    "result = df\n",
    "result = df[\"Column1\"]\n",
    "result = type(df[\"Column1\"])\n",
    "result = df[[\"Column1\",\"Column2\"]]\n",
    "# satıra göre seçme işlemleri\n",
    "\n",
    "# loc[\"row\",\"column\"] tek başına wo--row gönderilebilir.Column göndermek istersek row yerine \": ifadesini koymak gerekir.\"\n",
    "result = df.loc[\"A\"] #location kısaltmasıdır. a satırındaki elemanları getirir.\n",
    "result = type(df.loc[\"A\"])\n",
    "result = df.iloc[2] # indexte integer ile çalışmak istiyorsak kullanılır.\n",
    "result = df.loc[:,\"Column1\"]\n",
    "result = df.loc[:,[\"Column1\",\"Column2\"]]\n",
    "\n",
    "result = df.loc[:,\"Column1\":\"Column3\"] # aralık belirtilir. column1 ve 3 arasındaki onlarda dahil olarak getirilir.\n",
    "result = df.loc[:,:\"Column3\"]\n",
    "result = df.loc[\"A\":\"B\",:\"Column3\"]\n",
    "\n",
    "result = df.loc[\"A\",\"Column2\"]\n",
    "result = df.loc[[\"A\",\"B\"],[\"Column1\",\"Column2\"]]\n",
    "\n",
    "\n",
    "df[\"Column4\"] = pd.Series(randn(3),[\"A\",\"B\",\"C\"])\n",
    "df[\"Column5\"] = df[\"Column1\"] + df[\"Column2\"]\n",
    "result = df.drop(\"Column5\", axis = 1, inplace = True)\n",
    "# drop silme işlemi yapar. kalıcı olarak değilde kopyasını çıkarmak istersek inplace false olarak kullanırız default değeri zaten false.\n",
    "# kalıcı olarak silmek istersek inplace değerini true olarak değiştirebiliriz.\n",
    "\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eda829a",
   "metadata": {},
   "source": [
    "DateFrame Filtreleme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "8a0228d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Column1  Column2\n",
      "4       56       68\n",
      "5       92       98\n",
      "7       64       48\n",
      "9       64       55\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data = np.random.randint(10,100,75).reshape(15,5)\n",
    "\n",
    "df = pd.DataFrame(data, columns = [\"Column1\",\"Column2\",\"Column3\",\"Column4\",\"Column5\"])\n",
    "\n",
    "result = df\n",
    "result = df.columns\n",
    "result = df.head(5)\n",
    "result = df.head(10) # baştan ilk 10 kayıt getirilir.\n",
    "result = df.tail(5) # sondan ilk5 kayıt getirilir.\n",
    "result = df[\"Column1\"].head(5) #Colummn1 in ilk 5 kaydını getirir.\n",
    "result = df.Column1.head(5) #alternatif olarak kulllanıllabilir.\n",
    "result = df[[\"Column1\",\"Column3\"]].head(5)\n",
    "result = df[5:15][[\"Column1\",\"Column2\"]].tail(5)\n",
    "\n",
    "result = df > 50 \n",
    "result = df[df > 50]  # true false değilde sayı olarak istersek\n",
    "result = df[df % 2 == 0]  # true false değilde sayı olarak istersek\n",
    "result = df[df[\"Column1\"] > 50][[\"Column1\",\"Column2\"]]\n",
    "result = df[ (df[\"Column1\"] >= 50) & (df[\"Column1\"] <= 70)] # and yerine & kulllanılır.\n",
    "result = df[ (df[\"Column1\"] >= 50) & (df[\"Column2\"] <= 70)] # and yerine & kulllanılır.\n",
    "result = df[ (df[\"Column1\"] >= 50) | (df[\"Column2\"] <= 70)][[\"Column1\",\"Column2\"] ]# or yerine | kulllanılır.\n",
    "result = df.query(\"Column1 >= 50 & Column1 % 2 == 0\")[[\"Column1\",\"Column2\"]]\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f01bc7c8",
   "metadata": {},
   "source": [
    "Pandas Uygulama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ec474900",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('imdb.csv')\n",
    "\n",
    "result = df\n",
    "result = df.columns\n",
    "result = df.info # dataframe hakkında bir bilgi getirir.\n",
    "result = df.head(5)\n",
    "result = df.head(10)\n",
    "result = df.tail(5)\n",
    "result = df.tail(10)\n",
    "result = df[\"Movie_Title\"].head(5)\n",
    "result = df[[\"Movie_Title\",\"Rating\"]].head(5)\n",
    "result = df[[\"Movie_Title\",\"Rating\"]].tail(7)\n",
    "result = df[5:10][[\"Movie_Title\",\"Rating\"]]\n",
    "result = df[df[\"Movie_Title\"] & [\"Rating\"] >= 8.0]# benim yaptığım\n",
    "result = df[df[\"Rating\"] >= 8.0][[\"Movie_Title\",\"Rating\"]].head(50)\n",
    "result = df.query(\"Mpvie_Title & Rating > 8.0\")\n",
    "result = df[ (df[\"year\"] >= 2014) & ( [\"year\"] <= 2015) ][[\"Movie_Title\",\"year\"]]\n",
    "result = df[ (df[\"Num_Reviews\"] > 100000) |((df[\"Rating\"]  >= 8.0 )& (df[\"Rating\"] <= 9))][[\"Movie_Tilte\",\"Num_Reviews\",\"Rating\"]]\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "021ff0d9",
   "metadata": {},
   "source": [
    "DataFrame ' lerde Groupby kullanımı"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "70cf9ee4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sum     10500.0\n",
      "mean     5250.0\n",
      "amax     6500.0\n",
      "amin     4000.0\n",
      "Name: Muhasebe, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data = {\n",
    "    \"isimler\" : [\"Ahmet\",\"Can\",\"Hasan\",\"Cenk\",\"Ali\",\"Rıza\",\"Mustafa\"],\n",
    "    \"departman\" : [\"İK\",\"Bilgi İşlem\",\"Muhasebe\",\"İK\",\"Bilgi İşlem\",\"Muhasebe\",\"Bilgi İşlem\"],\n",
    "    \"yas\"  : [30, 25, 45, 50, 23, 34, 42],\n",
    "    \"semt\" : [\"Kadıköy\",\"Tuzla\",\"Maltepe\",\"Tuzla\",\"Kadıköy\",\"Tuzla\",\"Maltepe\"],\n",
    "    \"maas\" : [5000, 3000, 4000, 3500, 2750, 6500, 4500]\n",
    "}\n",
    "        \n",
    "df = pd.DataFrame(data)\n",
    "result = df[\"maas\"].sum()\n",
    "result = df\n",
    "\n",
    "result = df.groupby(\"departman\").groups\n",
    "result = df.groupby([\"departman\",\"semt\"]).groups\n",
    "\n",
    "# for name,group in df.groupby(\"semt\"): # semt kolonundaki verileri gruplandırır.\n",
    "#     print(name)\n",
    "#     print(group)\n",
    "# for name,group in df.groupby(\"departman\"):\n",
    "#     print(name) #semt adı\n",
    "#     print(group) # o semtte bulunan kişilerin verilerini gruplar\n",
    "\n",
    "result = df.groupby(\"semt\").get_group(\"Kadıköy\") # SEMT GRUBUNUNN İÇİNDEN KADIKÖYDE OLAN VERİLERİ GETİRİR.\n",
    "result = df.groupby(\"departman\").get_group(\"Muhasebe\")\n",
    "\n",
    "result = df.groupby(\"departman\").sum()\n",
    "result = df.groupby(\"departman\").mean()\n",
    "result = df.groupby(\"departman\")[\"maas\"].mean()\n",
    "result = df.groupby(\"semt\")[\"yas\"].mean()\n",
    "result = df.groupby(\"semt\")[\"maas\"].mean()\n",
    "result = df.groupby(\"semt\")[\"isimler\"].count()\n",
    "result = df.groupby(\"departman\")[\"yas\"].max()\n",
    "result = df.groupby(\"departman\")[\"maas\"].min()[\"Muhasebe\"]\n",
    "\n",
    "result = df.groupby(\"departman\").agg(np.mean)\n",
    "result = df.groupby(\"departman\")[\"maas\"].agg([np.sum,np.mean,np.max,np.min]).loc[\"Muhasebe\"]\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8de650d8",
   "metadata": {},
   "source": [
    "Pandas ile Kayıp veya bozuk veri analizi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8a4dc5bb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Column1    Column2    Column3    Column4\n",
      "a  80.000000  43.000000  10.000000  43.578947\n",
      "b  43.578947  43.578947  43.578947  30.000000\n",
      "c  19.000000  69.000000  20.000000  43.578947\n",
      "d  43.578947  43.578947  43.578947  51.000000\n",
      "e  29.000000  18.000000  26.000000  43.578947\n",
      "f  77.000000  80.000000  68.000000  30.000000\n",
      "g  43.578947  43.578947  43.578947  43.578947\n",
      "h  17.000000  75.000000  76.000000  10.000000\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data = np.random.randint(10,100,15).reshape(5,3)\n",
    "df = pd.DataFrame(data, index = ['a','c','e','f','h'], columns = ['Column1','Column2','Column3'])\n",
    "df = df.reindex(['a','b','c','d','e','f','g','h'])\n",
    "\n",
    "newColumn = [np.nan,30,np.nan,51,np.nan,30,np.nan,10] \n",
    "df[\"Column4\"] = newColumn\n",
    "\n",
    "result = df\n",
    "\n",
    "result = df.drop([\"Column1\",\"Column2\"], axis = 1) # 0 satıra 1 ise sütuna denk gelir.\n",
    "result = df.drop([\"a\"], axis = 0)\n",
    "\n",
    "\n",
    "result = df.isnull()\n",
    "result = df.notnull()# null olmayan alanları getirir.\n",
    "\n",
    "result = df.isnull().sum()# null ise true değer döndürür. sum ile bunlar toplanır.\n",
    "result = df[df[\"Column1\"].isnull()]\n",
    "result = df[df[\"Column1\"].notnull()][\"Column1\"]\n",
    "\n",
    "\n",
    "result = df.dropna(axis = 1) # axis = 0 varsayılan olarak gelir.\n",
    "result = df.dropna(how  = \"any\") # en az bir tane varsa\n",
    "result = df.dropna(how  = \"all\") # hepsi null ise getirmez.\n",
    "result = df.dropna(subset = [\"Column1\",\"Column2\"],how = \"all\")# sadece Column1 ve Column2 de ara\n",
    "result = df.dropna(subset = [\"Column1\",\"Column2\"],how = \"any\")\n",
    "result = df.dropna(thresh = 2) #en az 2 tane değer varsa silmez.\n",
    "result = df.dropna(thresh = 3)\n",
    "\n",
    "result = df.fillna(value = \"no input\") # boş alanlara no input yazar.\n",
    "\n",
    "result = df.sum() # her sütundaki sayıların toplamını getirir.\n",
    "result = df.sum().sum() # toplam sayısal değeri verir.\n",
    "result = df.size\n",
    "result = df.isnull().sum()\n",
    "result = df.isnull().sum().sum()\n",
    "\n",
    "\n",
    "def ortalama(df):\n",
    "    toplam = df.sum().sum()\n",
    "    adet = df.size - df.isnull().sum().sum()\n",
    "    return toplam / adet\n",
    "\n",
    "result = df.fillna(value = ortalama(df))\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1228ea68",
   "metadata": {},
   "source": [
    "Pandas ile String Fonksiyonları"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "642f83f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv(\"nba.csv\")\n",
    "\n",
    "data.dropna(inplace = True)\n",
    "\n",
    "data[\"Name\"] = data[\"Name\"].str.upper() # str yazdıktan sonra string metotlarına ulaşılabilir.\n",
    "data[\"Name\"] = data[\"Name\"].str.lower()\n",
    "data[\"index\"] = data[\"Name\"].str.find('a')\n",
    "data = data.Name.str.contains(\"Jordan\")\n",
    "data = data.Team.str.replace(' ','-')\n",
    "data[[\"FirstName\",\"LastName\"]] = data[\"Name\"].loc[data[\"Name\"].str.split().str.len() == 2].str.split(expand==True)\n",
    "\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2f9baf9",
   "metadata": {},
   "source": [
    "Pandas ile Join ve Merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e3a3a2f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   CustemorId FirstName LastName\n",
      "0           1     Ahmet   Yılmaz\n",
      "1           2       Ali  Korkmaz\n",
      "2           3     Hasan    Çelik\n",
      "3           4     Canan   Toprak\n",
      "0           1     Ahmet   Yılmaz\n",
      "1           2       Ali  Korkmaz\n",
      "2           3     Hasan    Çelik\n",
      "3           4     Canan   Toprak\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# customers = {\n",
    "#     'CustemorId': [1,2,3,4],\n",
    "#     'FirstName' : [\"Ahmet\",\"Ali\",\"Hasan\",\"Canan\"],\n",
    "#     \"LastName\" : [\"Yılmaz\",\"Korkmaz\",\"Çelik\",\"Toprak\"]\n",
    "# }\n",
    "# orders = {\n",
    "#     'OrderId': [10,11,12,13],\n",
    "#     'CustemorId': [1,2,5,7],\n",
    "#     'OrderDate' : ['2010-07-04' , '2010-07-07','2012-07-04','2000-11-04']\n",
    "# }\n",
    "\n",
    "# df_customers = pd.DataFrame(customers, columns = [\"CustemorId\",\"FirstName\",\"LastName\"])\n",
    "# df_orders = pd.DataFrame(orders, columns = [\"OrderId\", \"CustemorId\",\"OrderDate\"])\n",
    "\n",
    "\n",
    "# print(df_customers)\n",
    "# print(df_orders)\n",
    "\n",
    "# result = pd.merge(df_customers,df_orders,how = \"inner\") #2 tablo birleştirilir.\n",
    "# result = pd.merge(df_customers,df_orders,how = \"left\") # soldakileri getir sağdakileri getirme\n",
    "# result = pd.merge(df_customers,df_orders,how = \"right\") # aynı şekilde sağdakileri getir.\n",
    "\n",
    "\n",
    "customersA = {\n",
    "    'CustemorId': [1,2,3,4],\n",
    "    'FirstName' : [\"Ahmet\",\"Ali\",\"Hasan\",\"Canan\"],\n",
    "    \"LastName\" : [\"Yılmaz\",\"Korkmaz\",\"Çelik\",\"Toprak\"]\n",
    "}\n",
    "customersB = {\n",
    "    'CustemorId': [5,6,7,8],\n",
    "    'FirstName' : [\"Yağmur\",\"Çınar\",\"Cengiz\",\"Can\"],\n",
    "    \"LastName\" : [\"Bilge\",\"Turan\",\"Yılmaz\",\"Turan\"]\n",
    "}\n",
    "\n",
    "df_customersA = pd.DataFrame(customers, columns = [\"CustemorId\",\"FirstName\",\"LastName\"])\n",
    "df_customersB = pd.DataFrame(customers, columns = [\"CustemorId\",\"FirstName\",\"LastName\"])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "result = pd.concat([df_customersA,df_customersB])\n",
    "# Birleştirme işlemi yapılır.\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74658897",
   "metadata": {},
   "source": [
    "Pandas ile DataFrame Metotları"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5858872d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kategori  Elektronik  Kitap\n",
      "Ay                         \n",
      "Haziran           41     34\n",
      "Mayıs             20     13\n",
      "Nisan             15     42\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# data = {\n",
    "#     \"Column1\" : [1,2,3,4,5],\n",
    "#     \"Column2\" : [10,20,13,45,25],\n",
    "#     \"Column3\" : [\"abc\",\"ca\",\"aded\",\"ba\",\"dea\"]\n",
    "# }\n",
    "\n",
    "# df = pd.DataFrame(data)\n",
    "# result = df\n",
    "# result = df[\"Column2\"].unique() # tekrarlanmayan değerleri getirir.\n",
    "# result = df[\"Column2\"].nunique() # tekrarlanmayan değerlerin sayısını getirir.\n",
    "# result = df[\"Column2\"].value_counts() # eleman sayısını verir.\n",
    "# result = df[\"Column1\"] * 2\n",
    "\n",
    "\n",
    "# def kareal(x):\n",
    "#     return x * x\n",
    "# kareal2 = lambda x: x * x\n",
    "\n",
    "\n",
    "# result = df[\"Column1\"].apply(kareal2) # apply metoduna fonksiyon gönderilebilir teker teker fonksiyona değerler gider.\n",
    "# df[\"Column4\"] = df[\"Column3\"].apply(len)\n",
    "\n",
    "# result = df.columns\n",
    "# result = len(df.columns)\n",
    "# result = len(df.index)\n",
    "\n",
    "\n",
    "# result = df.info\n",
    "# result = df.sort_values(\"Column2\")\n",
    "# result = df.sort_values(\"Column3\",ascending = False) # ascending false artandan azalana doğru sıralar.\n",
    "\n",
    "data = {\n",
    "    \"Ay\" : [\"Mayıs\",\"Haziran\",\"Nisan\",\"Mayıs\",\"Haziran\",\"Nisan\",\"Mayıs\",\"Haziran\",\"Haziran\"],\n",
    "    \"Kategori\" : [\"Elektronik\",\"Elektronik\",\"Elektronik\",\"Kitap\",\"Kitap\",\"Kitap\",\"Kitap\",\"Kitap\",\"Elektronik\"],\n",
    "    \"Gelir\" : [20,30,15,14,32,42,12,36,52]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "df = df.pivot_table(index=\"Ay\",columns = \"Kategori\", values = \"Gelir\")\n",
    "\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2930e75d",
   "metadata": {},
   "source": [
    "Nba Verileri (Uygulama)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "538ba1b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Name                    Team  Number Position   Age Height  \\\n",
      "52        Carl Landry      Philadelphia 76ers     7.0       PF  32.0    6-9   \n",
      "78       Andrew Bogut   Golden State Warriors    12.0        C  31.0    7-0   \n",
      "83     Andre Iguodala   Golden State Warriors     9.0       SF  32.0    6-6   \n",
      "87       Brandon Rush   Golden State Warriors     4.0       SF  30.0    6-6   \n",
      "94     Branden Dawson    Los Angeles Clippers    22.0       SF  23.0    6-6   \n",
      "98     DeAndre Jordan    Los Angeles Clippers     6.0        C  27.0   6-11   \n",
      "106      Brandon Bass      Los Angeles Lakers     2.0       PF  31.0    6-8   \n",
      "115     Julius Randle      Los Angeles Lakers    30.0       PF  21.0    6-9   \n",
      "127    Brandon Knight            Phoenix Suns     3.0       PG  24.0    6-3   \n",
      "137    James Anderson        Sacramento Kings     5.0       SG  27.0    6-6   \n",
      "149     Eric Moreland        Sacramento Kings    25.0       PF  24.0   6-10   \n",
      "188    Andre Drummond         Detroit Pistons     0.0        C  22.0   6-11   \n",
      "227   Justin Anderson        Dallas Mavericks     1.0       SG  22.0    6-6   \n",
      "238  Chandler Parsons        Dallas Mavericks    25.0       SF  27.0   6-10   \n",
      "248  Andrew Goudelock         Houston Rockets     0.0       PG  27.0    6-3   \n",
      "259    Chris Andersen       Memphis Grizzlies     7.0       PF  37.0   6-10   \n",
      "271     Zach Randolph       Memphis Grizzlies    50.0       PF  34.0    6-9   \n",
      "274    Brandan Wright       Memphis Grizzlies    34.0       PF  28.0   6-10   \n",
      "276     Ryan Anderson    New Orleans Pelicans    33.0       PF  28.0   6-10   \n",
      "291   Orlando Johnson    New Orleans Pelicans     0.0       SG  27.0    6-5   \n",
      "295     Kyle Anderson       San Antonio Spurs     1.0       SF  22.0    6-9   \n",
      "304      Andre Miller       San Antonio Spurs    24.0       PG  40.0    6-3   \n",
      "362  Andrew Nicholson           Orlando Magic    44.0       PF  26.0    6-9   \n",
      "368     Alan Anderson      Washington Wizards     6.0       SG  33.0    6-6   \n",
      "386   Wilson Chandler          Denver Nuggets    21.0       SF  29.0    6-8   \n",
      "411    Andrew Wiggins  Minnesota Timberwolves    22.0       SG  21.0    6-8   \n",
      "415        Randy Foye   Oklahoma City Thunder     6.0       SG  32.0    6-4   \n",
      "423    Andre Roberson   Oklahoma City Thunder    21.0       SG  24.0    6-7   \n",
      "427   Cliff Alexander  Portland Trail Blazers    34.0       PF  20.0    6-8   \n",
      "\n",
      "     Weight           College      Salary  \n",
      "52    248.0            Purdue   6500000.0  \n",
      "78    260.0              Utah  13800000.0  \n",
      "83    215.0           Arizona  11710456.0  \n",
      "87    220.0            Kansas   1270964.0  \n",
      "94    225.0    Michigan State    525093.0  \n",
      "98    265.0         Texas A&M  19689000.0  \n",
      "106   250.0               LSU   3000000.0  \n",
      "115   250.0          Kentucky   3132240.0  \n",
      "127   189.0          Kentucky  13500000.0  \n",
      "137   213.0    Oklahoma State   1015421.0  \n",
      "149   238.0      Oregon State    845059.0  \n",
      "188   279.0       Connecticut   3272091.0  \n",
      "227   228.0          Virginia   1449000.0  \n",
      "238   230.0           Florida  15361500.0  \n",
      "248   200.0        Charleston    200600.0  \n",
      "259   245.0     Blinn College   5000000.0  \n",
      "271   260.0    Michigan State   9638555.0  \n",
      "274   210.0    North Carolina   5464000.0  \n",
      "276   240.0        California   8500000.0  \n",
      "291   220.0  UC Santa Barbara     55722.0  \n",
      "295   230.0              UCLA   1142880.0  \n",
      "304   200.0              Utah    250750.0  \n",
      "362   250.0   St. Bonaventure   2380593.0  \n",
      "368   220.0    Michigan State   4000000.0  \n",
      "386   225.0            DePaul  10449438.0  \n",
      "411   199.0            Kansas   5758680.0  \n",
      "415   213.0         Villanova   3135000.0  \n",
      "423   210.0          Colorado   1210800.0  \n",
      "427   240.0            Kansas    525093.0  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv(\"nba.csv\")\n",
    "\n",
    "result = df\n",
    "\n",
    "result = df.head(10)\n",
    "result = len(df.index)\n",
    "result = df[\"Salary\"].mean()\n",
    "result = df[\"Salary\"].max()\n",
    "result = df[\"Salary\"].max()\n",
    "result = df[df[\"Salary\"] == df[\"Salary\"].max()][\"Name\"].iloc[0]\n",
    "result = (df[(df[\"Age\"] >= 20 ) & (df[\"Age\"] < 25)])[[\"Name\",\"Team\",\"Age\"]]\n",
    "result = df[df[\"Name\"] == \"John Holland\"][\"Team\"]\n",
    "result = df.groupby(\"Team\")[\"Salary\"].mean()\n",
    "result = len(df.groupby(\"Team\"))\n",
    "result = df[\"Team\"].nunique()\n",
    "result = df[\"Team\"].value_counts()\n",
    "\n",
    "df.dropna(inplace = True) # null değerler silinir\n",
    "result = df[df[\"Name\"].str.contains(\"and\")]\n",
    "\n",
    "\n",
    "\n",
    "def str_find(name):\n",
    "    if \"and\" in name.lower():\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "result = df[df[\"Name\"].apply(str_find)] # str_find referans olarak gönderilir.\n",
    "\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b649e951",
   "metadata": {},
   "source": [
    "Youtube istatistik verilerin analizi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "2a7a3d69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          video_id trending_date  \\\n",
      "36631  N1HAMUAXzbs      18.01.06   \n",
      "7088   sVfTvLm-7Ac      17.19.12   \n",
      "5361   vPsic3dEndc      17.10.12   \n",
      "12082  6W45zR0knjg      18.15.01   \n",
      "5338   r81egea0QPo      17.10.12   \n",
      "...            ...           ...   \n",
      "21547  BhIEIO0vaBE      18.03.03   \n",
      "22661  c0arVTRwytA      18.09.03   \n",
      "24920  ixNNLvyCn5Y      18.20.03   \n",
      "14864  nQ7mhC5_Rys      18.29.01   \n",
      "4465   nx1R-eHSkfM      17.06.12   \n",
      "\n",
      "                                                   title       channel_title  \\\n",
      "36631         Kris Wu – Like That (Official Music Video)             Kris Wu   \n",
      "7088      HIGHLIGHTS: MK Dons U18s 1-0 Cardiff City U18s             MK Dons   \n",
      "5361         QUIZ : Name the Trail : A Christmas Cracker   The 2Inch of Gnar   \n",
      "12082    Lima Sopoaga Tribute🔥🔥||The Unsung Hero||💯 2017   The rugby channel   \n",
      "5338   Bohemian Rhapsody (2018) - Scene Bohemian Rhap...      NanoO ARCHIVOS   \n",
      "...                                                  ...                 ...   \n",
      "21547                                    To Our Daughter        Kylie Jenner   \n",
      "22661                      【公式】「劇場版ポケットモンスター みんなの物語」予告編1  ポケモン公式YouTubeチャンネル   \n",
      "24920                    映画『BLEACH』特報【HD】2018年7月20日（金）公開  ワーナー ブラザース 公式チャンネル   \n",
      "14864                             Altwork 1 Minute Video             altwork   \n",
      "4465                      The New Snapchat in 60 Seconds            Snapchat   \n",
      "\n",
      "       category_id              publish_time  \\\n",
      "36631           10  2018-05-22T15:05:18.000Z   \n",
      "7088            17  2017-12-13T16:33:57.000Z   \n",
      "5361            22  2017-12-01T11:34:30.000Z   \n",
      "12082           17  2017-09-29T21:46:38.000Z   \n",
      "5338             1  2017-11-02T18:30:38.000Z   \n",
      "...            ...                       ...   \n",
      "21547           22  2018-02-04T20:27:38.000Z   \n",
      "22661            1  2018-02-27T01:00:03.000Z   \n",
      "24920            1  2018-02-21T05:17:53.000Z   \n",
      "14864           28  2017-01-21T00:12:02.000Z   \n",
      "4465            10  2017-11-29T14:00:03.000Z   \n",
      "\n",
      "                                                    tags     views  likes  \\\n",
      "36631  Kris Wu|\"Wu Yi Fan\"|\"吴亦凡\"|\"fan shi\"|\"wuyifan\"|...  12230325  57544   \n",
      "7088                 Tommy Hope|\"MK Dons\"|\"Cardiff City\"     21530     30   \n",
      "5361   MTB|\"Mountain Biking\"|\"Bike\"|\"Bird\"|\"Aeris\"|\"B...      1218      2   \n",
      "12082                                             [none]     10869     50   \n",
      "5338   Bohemian Rhapsody Live AID|\"freddie mercury fi...     10142     71   \n",
      "...                                                  ...       ...    ...   \n",
      "21547  Kylie Jenner|\"Kylie\"|\"Travis Scott\"|\"Baby\"|\"An...  61080912      0   \n",
      "22661  pokemon|\"Pokémon\"|\"ポケモン\"|\"ポケットモンスター\"|\"みんなの物語\"|...   1234846      0   \n",
      "24920  ブリーチ|\"BLEACH\"|\"福士蒼汰\"|\"佐藤信介\"|\"週刊少年ジャンプ\"|\"完結\"|\"久...   1421802      0   \n",
      "14864                                             [none]     50522      0   \n",
      "4465   new snapchat|\"version 2\"|\"snap inc\"|\"brandnew\"...   3449247      0   \n",
      "\n",
      "       dislikes  comment_count  video_error_or_removed  \\\n",
      "36631         0           9528                   False   \n",
      "7088          0              2                   False   \n",
      "5361          0              1                   False   \n",
      "12082         0             14                   False   \n",
      "5338          0             20                   False   \n",
      "...         ...            ...                     ...   \n",
      "21547         0              0                   False   \n",
      "22661         0              0                   False   \n",
      "24920         0              0                   False   \n",
      "14864         0              0                   False   \n",
      "4465          0              0                   False   \n",
      "\n",
      "                                             description  title_len  \\\n",
      "36631  Special thanks to Stella Maxwell.Get “Like Tha...         42   \n",
      "7088   Check out Tommy Hope's stunning winner in the ...         46   \n",
      "5361   A Bad Brains Christmas Cracker! - #NameTheTrai...         43   \n",
      "12082  Hope You Enjoyed The Video \\n-----------------...         47   \n",
      "5338   Queen - Bohemian Rhapsody Live AID \\n\\nSUSCRIB...         59   \n",
      "...                                                  ...        ...   \n",
      "21547  Directed by Tyler Ross @wttyler\\nMusic by Jaco...         15   \n",
      "22661  2018年7月13日（金）公開 「劇場版ポケットモンスター みんなの物語」\\n映画公式サイト...         29   \n",
      "24920  死神、見参。\\n\\n全世界累計発行部数1億2,000万部の国民的人気コミックが実写映画化！悪...         31   \n",
      "14864                                                NaN         22   \n",
      "4465   Evan Spiegel, co-founder and CEO, explains the...         30   \n",
      "\n",
      "       tag_count  begeni_orani  \n",
      "36631          9           1.0  \n",
      "7088           3           1.0  \n",
      "5361          22           1.0  \n",
      "12082          1           1.0  \n",
      "5338          16           1.0  \n",
      "...          ...           ...  \n",
      "21547          5           0.0  \n",
      "22661         18           0.0  \n",
      "24920         25           0.0  \n",
      "14864          1           0.0  \n",
      "4465          11           0.0  \n",
      "\n",
      "[38916 rows x 16 columns]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_10292\\3100592909.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"begeni_orani\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlikedislikeoranhesapla\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 47\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"begeni_orani\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mascending\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"title\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"dislikes\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"begeni_orani\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"youtube-ing.csv\")\n",
    "\n",
    "result = df\n",
    "result = df.head(10)\n",
    "result = df[5:10].head(5) # gruplayıp kayıtların ilk 5ini alırız.\n",
    "# result = len(df.columns.name)\n",
    "result = df.drop([\"thumbnail_link\",\"comments_disabled\",\"ratings_disabled\"] ,axis = 1,inplace=True)\n",
    "result = df\n",
    "result = df[\"likes\"].mean()\n",
    "result = df[\"dislikes\"].mean()\n",
    "result = df.head(50)[[\"title\",\"likes\",\"dislikes\"]]\n",
    "\n",
    "result = df [df[\"views\"].max() == df[\"views\"]][\"title\"].iloc[0]\n",
    "result = df [df[\"views\"].min() == df[\"views\"]][\"title\"].iloc[0]\n",
    "result = df.sort_values(\"views\",ascending = False).head(10)[\"title\"]\n",
    "\n",
    "\n",
    "result = df.groupby(\"category_id\").mean().sort_values(\"likes\")[\"likes\"]\n",
    "result = df.groupby(\"category_id\").sum().sort_values(\"comment_count\",ascending = False)\n",
    "\n",
    "result = df[\"category_id\"].value_counts()\n",
    "df[\"title_len\"] = df[\"title\"].apply(len)\n",
    "\n",
    "def tagCount(tag):\n",
    "    return len(tag.split(\"|\"))\n",
    "\n",
    "df[\"tag_count\"] = df[\"tags\"].apply(tagCount)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def likedislikeoranhesapla(dataset):\n",
    "    likesList = list(df[\"likes\"])\n",
    "    dislikesList = list(df[\"dislikes\"])\n",
    "    liste = list(zip(likesList,dislikesList))\n",
    "    oranListesi = []\n",
    "    for like,dislike in liste:\n",
    "        if (like + dislike) == 0:\n",
    "            oranListesi.append(0)\n",
    "        else:\n",
    "            oranListesi.append(like/(like+dislike))\n",
    "    return oranListesi\n",
    "    \n",
    "df[\"begeni_orani\"] = likedislikeoranhesapla(df)\n",
    "print(df.sort_values(\"begeni_orani\",ascending = False))[[\"title\",\"dislikes\",\"begeni_orani\"]]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
